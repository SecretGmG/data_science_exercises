{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Week 5 - Assignment</center></h2>\n",
    "<h3><center>Programming for Data Science 2025</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises for the topics covered in the fifth lecture.\n",
    "\n",
    "The exercise will be marked as passed if you get **at least 10/17** points.\n",
    "\n",
    "Exercises must be handed in via **ILIAS** (Homework assignments). Deliver your submission as a compressed file (zip) containing one .py or .ipynb file with all exercises. The name of both the .zip and the .py/.ipynb file must be *SurnameName* of the two members of the group. Example: Annina Helmy + Markus Anwander = *HelmyAnnina_AnwanderMarkus.zip* .\n",
    "\n",
    "It's important to use comments to explain your code and show that you're able to take ownership of the exercises and discuss them.\n",
    "\n",
    "You are not expected to collaborate outside of the group on exercises and submitting other groupsâ€™ code as your own will result in 0 points.\n",
    "\n",
    "For question about the lecture content or exam, contact: *annina.helmy@students.unibe.ch* with the subject: *Programming for Data Science 2025 - Lecture XY*.\n",
    "For questions about the excercise/grading of excercises, contact: *thea.waldleben@students.unibe.ch* or *patricia.gribi@students.unibe.ch* with the subject: *Programming for Data Science 2025 - Excercise XY*.\n",
    "\n",
    "**Deadline: 14:00, March 27, 2025.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Exercise 1 - Fitbit dataset<span style=\"float: right\">3 points</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with three datasets - 'activity.csv', 'calories.csv', and 'last_participant.csv', which contains activity tracker data from https://www.kaggle.com/datasets/arashnic/fitbit\n",
    "\n",
    "If you are unable to do this exercise, you can load the dataset 'combined_solution.csv' for the next exercise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Data preparation** (*1 point*)\n",
    "\n",
    "    - Load the two datasets 'activity.csv' and 'calories.csv'.\n",
    "    - Use pd.to_datetime to standardize the ActivityDate columns (https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/activity.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m###\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m###\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m activity_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/activity.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m calories_df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mdata/calories.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m activity_df[\u001b[33m'\u001b[39m\u001b[33mActivityDate\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(activity_df[\u001b[33m'\u001b[39m\u001b[33mActivityDate\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wolfi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wolfi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wolfi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wolfi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wolfi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/activity.csv'"
     ]
    }
   ],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###\n",
    "\n",
    "activity_df = pd.read_csv('data/activity.csv')\n",
    "calories_df = pd.read_csv('data/calories.csv')\n",
    "\n",
    "activity_df['ActivityDate'] = pd.to_datetime(activity_df['ActivityDate'])\n",
    "calories_df['ActivityDate'] = pd.to_datetime(calories_df['ActivityDate'])\n",
    "\n",
    "display(activity_df.head())\n",
    "display(calories_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Merging** (*1 point*)\n",
    "\n",
    "    - Consider what information is shared between the two datasets and merge them. Keep in mind that the order of rows is not the same in both datasets!\n",
    "    - Print out the mean \"TotalSteps\" of the merged DataFrame at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'activity_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m###\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m###\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# the default inner join should be fine\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m combined_df = pd.merge(\u001b[43mactivity_df\u001b[49m, calories_df)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmean Total Steps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined_df[\u001b[33m\"\u001b[39m\u001b[33mTotalSteps\u001b[39m\u001b[33m\"\u001b[39m].mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'activity_df' is not defined"
     ]
    }
   ],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###\n",
    "\n",
    "# the default inner join should be fine\n",
    "combined_df = pd.merge(activity_df, calories_df)\n",
    "print(f'mean Total Steps: {combined_df[\"TotalSteps\"].mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Concatenation** (*1 point*)\n",
    "\n",
    "    - The data of one additional participant exists in 'last_participant.csv'. Load this dataset and concatenate it with the merged dataset generated above\n",
    "    - Print out the mean \"TotalSteps\" again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ActivityDate",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "TotalSteps",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TotalDistance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VeryActiveDistance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ModeratelyActiveDistance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LightActiveDistance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VeryActiveMinutes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "FairlyActiveMinutes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "LightlyActiveMinutes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Calories",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e3aa4a42-850f-4770-9c97-e813e6fa9be5",
       "rows": [
        [
         "0",
         "1503960366",
         "2016-04-12 00:00:00",
         "13162.0",
         "8.5",
         "1.879999995",
         "0.550000012",
         "6.059999943",
         "25",
         "13",
         "328",
         "1985.0"
        ],
        [
         "1",
         "1503960366",
         "2016-04-13 00:00:00",
         "10735.0",
         "6.96999979",
         "1.570000052",
         "0.689999998",
         "4.710000038",
         "21",
         "19",
         "217",
         null
        ],
        [
         "2",
         "1503960366",
         "2016-04-14 00:00:00",
         "10460.0",
         "6.739999771",
         "2.440000057",
         "0.400000006",
         "3.910000086",
         "30",
         "11",
         "181",
         "1776.0"
        ],
        [
         "3",
         "1503960366",
         "2016-04-15 00:00:00",
         "9762.0",
         "6.28000021",
         "2.140000105",
         "1.25999999",
         "2.829999924",
         "29",
         "34",
         "209",
         "1745.0"
        ],
        [
         "4",
         "1503960366",
         "2016-04-16 00:00:00",
         "12669.0",
         "8.159999847",
         "2.710000038",
         "0.409999996",
         "5.039999962",
         "36",
         "10",
         "221",
         "1863.0"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ActivityDate</th>\n",
       "      <th>TotalSteps</th>\n",
       "      <th>TotalDistance</th>\n",
       "      <th>VeryActiveDistance</th>\n",
       "      <th>ModeratelyActiveDistance</th>\n",
       "      <th>LightActiveDistance</th>\n",
       "      <th>VeryActiveMinutes</th>\n",
       "      <th>FairlyActiveMinutes</th>\n",
       "      <th>LightlyActiveMinutes</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1503960366</td>\n",
       "      <td>2016-04-12</td>\n",
       "      <td>13162.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.55</td>\n",
       "      <td>6.06</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>328</td>\n",
       "      <td>1985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1503960366</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>10735.0</td>\n",
       "      <td>6.97</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.69</td>\n",
       "      <td>4.71</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>217</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1503960366</td>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>10460.0</td>\n",
       "      <td>6.74</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>181</td>\n",
       "      <td>1776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1503960366</td>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>9762.0</td>\n",
       "      <td>6.28</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.26</td>\n",
       "      <td>2.83</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>209</td>\n",
       "      <td>1745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1503960366</td>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>12669.0</td>\n",
       "      <td>8.16</td>\n",
       "      <td>2.71</td>\n",
       "      <td>0.41</td>\n",
       "      <td>5.04</td>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>221</td>\n",
       "      <td>1863.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID ActivityDate  TotalSteps  TotalDistance  VeryActiveDistance  \\\n",
       "0  1503960366   2016-04-12     13162.0           8.50                1.88   \n",
       "1  1503960366   2016-04-13     10735.0           6.97                1.57   \n",
       "2  1503960366   2016-04-14     10460.0           6.74                2.44   \n",
       "3  1503960366   2016-04-15      9762.0           6.28                2.14   \n",
       "4  1503960366   2016-04-16     12669.0           8.16                2.71   \n",
       "\n",
       "   ModeratelyActiveDistance  LightActiveDistance  VeryActiveMinutes  \\\n",
       "0                      0.55                 6.06                 25   \n",
       "1                      0.69                 4.71                 21   \n",
       "2                      0.40                 3.91                 30   \n",
       "3                      1.26                 2.83                 29   \n",
       "4                      0.41                 5.04                 36   \n",
       "\n",
       "   FairlyActiveMinutes  LightlyActiveMinutes  Calories  \n",
       "0                   13                   328    1985.0  \n",
       "1                   19                   217       NaN  \n",
       "2                   11                   181    1776.0  \n",
       "3                   34                   209    1745.0  \n",
       "4                   10                   221    1863.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean Total Steps: 7786.439\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###\n",
    "last_participant_df = pd.read_csv('data/last_participant.csv')\n",
    "display(combined_df.head())\n",
    "print(f'mean Total Steps: {combined_df[\"TotalSteps\"].mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Exercise 2 - Working with missing data<span style=\"float: right\">5 points</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our dataset, some values are missing from the 'TotalSteps' and 'Calories' columns.\n",
    "\n",
    "We can try to approximate these missing values with the data we got. \n",
    "\n",
    "You can load the dataset 'combined_solution.csv' if you were unable to complete the previous exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Filling in missing values** (*3 points*)\n",
    "\n",
    "    - Calculate the mean steps per calory burnt and mean calories burnt per step, by averaging across all observations in the dataset and then computing the ratio. Print out both values.\n",
    "    - Fill in the null values in the columns 'Calories' and 'TotalSteps' where possible. To fill the values you have to use the factors *\"TotalSteps/Calories\"* and *\"Calories/TotalSteps\"* calculated in the previous point, using one of the two information to fill the other.\n",
    "    - Print out the mean of the columns 'TotalSteps' and 'Calories' before and after filling the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m###\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m###\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m filled_in_df = \u001b[43mcombined_df\u001b[49m.copy()\n\u001b[32m      7\u001b[39m mean_steps = combined_df[\u001b[33m'\u001b[39m\u001b[33mTotalSteps\u001b[39m\u001b[33m'\u001b[39m].mean()\n\u001b[32m      8\u001b[39m mean_calories = combined_df[\u001b[33m'\u001b[39m\u001b[33mCalories\u001b[39m\u001b[33m'\u001b[39m].mean()\n",
      "\u001b[31mNameError\u001b[39m: name 'combined_df' is not defined"
     ]
    }
   ],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###\n",
    "\n",
    "filled_in_df = combined_df.copy()\n",
    "\n",
    "mean_steps = combined_df['TotalSteps'].mean()\n",
    "mean_calories = combined_df['Calories'].mean()\n",
    "\n",
    "print(f'Means before filling in: \\nsteps : {mean_steps:.3f}\\ncalories : {mean_calories:.3f}')\n",
    "\n",
    "mask = combined_df['TotalSteps'].isna()\n",
    "filled_in_df.loc[mask, 'TotalSteps'] = combined_df.loc[mask, 'Calories'] * mean_steps / mean_calories\n",
    "\n",
    "mask = combined_df['Calories'].isna()\n",
    "filled_in_df.loc[mask, 'Calories'] = combined_df.loc[mask, 'TotalSteps'] * mean_calories / mean_steps\n",
    "\n",
    "\n",
    "print(f'Means after filling in: \\nsteps : {filled_in_df[\"TotalSteps\"].mean():.3f}\\ncalories : {filled_in_df[\"Calories\"].mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Dropping missing values** (*2 points*)\n",
    "\n",
    "    - Print how many null values there are in the 'Calories' and 'TotalSteps' columns, respectively.\n",
    "    - Drop the rows where **both** 'Calories' and 'TotalSteps' are missing.\n",
    "    - Print number of rows in the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calories      13\n",
      "TotalSteps    13\n",
      "dtype: int64\n",
      "909\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###\n",
    "\n",
    "print(filled_in_df[['Calories', 'TotalSteps']].isna().sum())\n",
    "filtered_df = filled_in_df.loc[filled_in_df['Calories'].isna() & filled_in_df['TotalSteps'].isna()]\n",
    "print(len(filled_in_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Exercise 3 - Multi-index<span style=\"float: right\">7 points</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will create and manipulate a multi-index dataframe. First, let's create the dataframe for the exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"idx\": [0, 1, 2],\n",
    "        \"A_X\": [1.1, 1.1, 1.1],\n",
    "        \"A_Y\": [1.2, 1.2, 1.2],\n",
    "        \"B_X\": [1.11, 1.11, 1.11],\n",
    "        \"B_Y\": [1.22, 1.22, 1.22],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set the column *idx* as the index of the dataframe. (*1 point*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A_X  A_Y   B_X   B_Y\n",
      "idx                      \n",
      "0    1.1  1.2  1.11  1.22\n",
      "1    1.1  1.2  1.11  1.22\n",
      "2    1.1  1.2  1.11  1.22\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###\n",
    "df.set_index('idx', inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a multi-column stucture. (*3 points*)\n",
    "    - Set the columns *A, B* on the first level and *X, Y* on the second level, taken from the combinations in the original dataframe. \n",
    "    - Set the names of the two new levels as \"L1\" and \"L2\", respectively. \n",
    "    - Print the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1     A          B      \n",
      "L2     X    Y     X     Y\n",
      "idx                      \n",
      "0    1.1  1.2  1.11  1.22\n",
      "1    1.1  1.2  1.11  1.22\n",
      "2    1.1  1.2  1.11  1.22\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###\n",
    "#create tuples from original by spliting the column 'name'\n",
    "tuples_list = [tuple(col.split(\"_\")) for col in df.columns]\n",
    "df.columns = pd.MultiIndex.from_tuples(tuples_list, names=[\"L1\",\"L2\"])\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. From the previous dataframe, re-create a dataframe with a single column level. (*3 points*)\n",
    "    - Create a new column from the first level (L1) of the multi-column. At this point your columns should be ['L1', 'X', 'Y'], with name 'L2'. **NB** The DataFrame method *reset_index* is useful for this part.\n",
    "    - Rename the newly-created column as \"letter\" and the name of the column level as \"L\". Use the appropiate pandas methods for this.\n",
    "    - Print the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2  idx L1     X     Y\n",
      "0     0  A  1.10  1.20\n",
      "1     0  B  1.11  1.22\n",
      "2     1  A  1.10  1.20\n",
      "3     1  B  1.11  1.22\n",
      "4     2  A  1.10  1.20\n",
      "5     2  B  1.11  1.22\n",
      "--------------\n",
      "L2  idx letter     X     Y\n",
      "0     0      A  1.10  1.20\n",
      "1     0      B  1.11  1.22\n",
      "2     1      A  1.10  1.20\n",
      "3     1      B  1.11  1.22\n",
      "4     2      A  1.10  1.20\n",
      "5     2      B  1.11  1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wolfi\\AppData\\Local\\Temp\\ipykernel_26276\\2497091152.py:5: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df = df.stack(level=0).reset_index()\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###\n",
    "#create new column with stack\n",
    "df = df.stack(level=0).reset_index()\n",
    "print(df)\n",
    "print(\"--------------\")\n",
    "df_names = df.rename(columns={'L1': 'letter'})\n",
    "df_names = df_names.rename_axis(index={'L2': 'L'})\n",
    "print(df_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Exercise 4 - .xs() vs. .loc - on paper <span style=\"float: right\">2 points</span></h3>\n",
    "\n",
    "Consider the following DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T19:44:13.550850Z",
     "start_time": "2025-03-19T19:44:13.297757Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/stock_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[148]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./data/stock_data.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m data = data.set_index([\u001b[33m\"\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mTicker\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      4\u001b[39m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wolfi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wolfi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wolfi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wolfi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wolfi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './data/stock_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./data/stock_data.csv')\n",
    "data = data.set_index([\"Date\", \"Ticker\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select the data for the company 'GOOGL' using the `.xs()` method.\n",
    "2. Select the data for the company 'AAPL' and the date '2022-12-30' using the `.xs()` method\n",
    "3. What would the equivalent be using the `.loc` method?\n",
    "4. What are the main differences between the two methods?\n",
    "5. When would you use one over the other?\n",
    "6. How would you pllot the 'Close' price for the company 'AAPL' using the `.xs()` method and matplotlib? Write the code and then check your implementation in your Jupyter Notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
